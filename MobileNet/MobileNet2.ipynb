{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "from torch import nn "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DepSepConv(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, stride):\n",
    "        super().__init__()\n",
    "\n",
    "        self.depthwise = nn.Sequential(nn.Conv2d(in_channels,in_channels,3, stride = stride, padding = 1, groups = in_channels, bias=False),\n",
    "                                       nn.BatchNorm2d(in_channels),\n",
    "                                       nn.ReLU6(inplace=True))\n",
    "\n",
    "        self.pointwise = nn.Sequential(nn.Conv2d(in_channels,out_channels,1, bias=False),\n",
    "                                       nn.BatchNorm2d(out_channels))\n",
    "                                       # no activation!!\n",
    "    def forward(self, x):\n",
    "        x = self.depthwise(x)\n",
    "        x = self.pointwise(x)\n",
    "        return x\n",
    "\n",
    "class InvertedBlock(nn.Module):\n",
    "    def __init__(self, in_channels, exp_channels, out_channels, stride):\n",
    "        super().__init__()\n",
    "\n",
    "        self.use_skip_connect = (stride==1 and in_channels==out_channels)\n",
    "\n",
    "        layers = []\n",
    "        if in_channels != exp_channels: # 채널 안늘어날 때는 1x1 생략. 즉, 1x1은 채널을 키워야할 때만 존재한다.\n",
    "            layers += [nn.Sequential(nn.Conv2d(in_channels, exp_channels, 1, bias=False),\n",
    "                                     nn.BatchNorm2d(exp_channels),\n",
    "                                     nn.ReLU6(inplace=True))]\n",
    "        layers += [DepSepConv(exp_channels, out_channels, stride=stride)]\n",
    "\n",
    "        self.residual = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        if self.use_skip_connect:\n",
    "            return x + self.residual(x) # 더하고 ReLU 하지 않는다! 그래야 linear block이 되는 거니까\n",
    "        else:\n",
    "            return self.residual(x)\n",
    "\n",
    "class MobileNetV2(nn.Module):\n",
    "    def __init__(self, num_classes=1000):\n",
    "        super().__init__()\n",
    "\n",
    "        self.configs=[# t, c, n, s\n",
    "                      [1, 16, 1, 1],\n",
    "                      [6, 24, 2, 2],\n",
    "                      [6, 32, 3, 2],\n",
    "                      [6, 64, 4, 2],\n",
    "                      [6, 96, 3, 1],\n",
    "                      [6, 160, 3, 2],\n",
    "                      [6, 320, 1, 1]]\n",
    "\n",
    "        self.stem_conv = nn.Sequential(nn.Conv2d(3, 32, 3, padding=1, stride=2, bias=False),\n",
    "                                       nn.BatchNorm2d(32),\n",
    "                                       nn.ReLU6(inplace=True))\n",
    "\n",
    "        in_channels = 32\n",
    "        layers = []\n",
    "        for t, c, n, s in self.configs:\n",
    "            for i in range(n):\n",
    "                stride = s if i == 0 else 1\n",
    "                exp_channels = in_channels * t\n",
    "                layers += [InvertedBlock(in_channels=in_channels, exp_channels=exp_channels, out_channels=c, stride=stride)]\n",
    "                in_channels = c\n",
    "\n",
    "        self.layers = nn.Sequential(*layers)\n",
    "\n",
    "        self.last_conv = nn.Sequential(nn.Conv2d(in_channels, 1280, 1, bias=False),\n",
    "                                       nn.BatchNorm2d(1280),\n",
    "                                       nn.ReLU6(inplace=True))\n",
    "        \n",
    "        self.avg_pool = nn.AdaptiveAvgPool2d((1,1))\n",
    "\n",
    "        self.classifier = nn.Sequential(nn.Dropout(0.2), # 논문에는 상세히 나와있진 않지만 토치 문서에 있어서 포함 -> 채널 축으로 특징들이 놓여있고 그것들을 일부 가려보며 학습하는 의미\n",
    "                                        nn.Linear(1280, num_classes))\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.stem_conv(x)\n",
    "        x = self.layers(x)\n",
    "        x = self.last_conv(x)\n",
    "        x = self.avg_pool(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.classifier(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "====================================================================================================\n",
       "Layer (type:depth-idx)                             Output Shape              Param #\n",
       "====================================================================================================\n",
       "MobileNetV2                                        [2, 1000]                 --\n",
       "├─Sequential: 1-1                                  [2, 32, 112, 112]         --\n",
       "│    └─Conv2d: 2-1                                 [2, 32, 112, 112]         864\n",
       "│    └─BatchNorm2d: 2-2                            [2, 32, 112, 112]         64\n",
       "│    └─ReLU6: 2-3                                  [2, 32, 112, 112]         --\n",
       "├─Sequential: 1-2                                  [2, 320, 7, 7]            --\n",
       "│    └─InvertedBlock: 2-4                          [2, 16, 112, 112]         --\n",
       "│    │    └─Sequential: 3-1                        [2, 16, 112, 112]         896\n",
       "│    └─InvertedBlock: 2-5                          [2, 24, 56, 56]           --\n",
       "│    │    └─Sequential: 3-2                        [2, 24, 56, 56]           5,136\n",
       "│    └─InvertedBlock: 2-6                          [2, 24, 56, 56]           --\n",
       "│    │    └─Sequential: 3-3                        [2, 24, 56, 56]           8,832\n",
       "│    └─InvertedBlock: 2-7                          [2, 32, 28, 28]           --\n",
       "│    │    └─Sequential: 3-4                        [2, 32, 28, 28]           10,000\n",
       "│    └─InvertedBlock: 2-8                          [2, 32, 28, 28]           --\n",
       "│    │    └─Sequential: 3-5                        [2, 32, 28, 28]           14,848\n",
       "│    └─InvertedBlock: 2-9                          [2, 32, 28, 28]           --\n",
       "│    │    └─Sequential: 3-6                        [2, 32, 28, 28]           14,848\n",
       "│    └─InvertedBlock: 2-10                         [2, 64, 14, 14]           --\n",
       "│    │    └─Sequential: 3-7                        [2, 64, 14, 14]           21,056\n",
       "│    └─InvertedBlock: 2-11                         [2, 64, 14, 14]           --\n",
       "│    │    └─Sequential: 3-8                        [2, 64, 14, 14]           54,272\n",
       "│    └─InvertedBlock: 2-12                         [2, 64, 14, 14]           --\n",
       "│    │    └─Sequential: 3-9                        [2, 64, 14, 14]           54,272\n",
       "│    └─InvertedBlock: 2-13                         [2, 64, 14, 14]           --\n",
       "│    │    └─Sequential: 3-10                       [2, 64, 14, 14]           54,272\n",
       "│    └─InvertedBlock: 2-14                         [2, 96, 14, 14]           --\n",
       "│    │    └─Sequential: 3-11                       [2, 96, 14, 14]           66,624\n",
       "│    └─InvertedBlock: 2-15                         [2, 96, 14, 14]           --\n",
       "│    │    └─Sequential: 3-12                       [2, 96, 14, 14]           118,272\n",
       "│    └─InvertedBlock: 2-16                         [2, 96, 14, 14]           --\n",
       "│    │    └─Sequential: 3-13                       [2, 96, 14, 14]           118,272\n",
       "│    └─InvertedBlock: 2-17                         [2, 160, 7, 7]            --\n",
       "│    │    └─Sequential: 3-14                       [2, 160, 7, 7]            155,264\n",
       "│    └─InvertedBlock: 2-18                         [2, 160, 7, 7]            --\n",
       "│    │    └─Sequential: 3-15                       [2, 160, 7, 7]            320,000\n",
       "│    └─InvertedBlock: 2-19                         [2, 160, 7, 7]            --\n",
       "│    │    └─Sequential: 3-16                       [2, 160, 7, 7]            320,000\n",
       "│    └─InvertedBlock: 2-20                         [2, 320, 7, 7]            --\n",
       "│    │    └─Sequential: 3-17                       [2, 320, 7, 7]            473,920\n",
       "├─Sequential: 1-3                                  [2, 1280, 7, 7]           --\n",
       "│    └─Conv2d: 2-21                                [2, 1280, 7, 7]           409,600\n",
       "│    └─BatchNorm2d: 2-22                           [2, 1280, 7, 7]           2,560\n",
       "│    └─ReLU6: 2-23                                 [2, 1280, 7, 7]           --\n",
       "├─AdaptiveAvgPool2d: 1-4                           [2, 1280, 1, 1]           --\n",
       "├─Sequential: 1-5                                  [2, 1000]                 --\n",
       "│    └─Dropout: 2-24                               [2, 1280]                 --\n",
       "│    └─Linear: 2-25                                [2, 1000]                 1,281,000\n",
       "====================================================================================================\n",
       "Total params: 3,504,872\n",
       "Trainable params: 3,504,872\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (M): 601.62\n",
       "====================================================================================================\n",
       "Input size (MB): 1.20\n",
       "Forward/backward pass size (MB): 213.72\n",
       "Params size (MB): 14.02\n",
       "Estimated Total Size (MB): 228.94\n",
       "===================================================================================================="
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = MobileNetV2()\n",
    "# print(model)\n",
    "\n",
    "from torchinfo import summary\n",
    "summary(model, input_size=(2,3,224,224), device='cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 1000])\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn(2,3,224,224)\n",
    "print(model(x).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TorchEnv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
